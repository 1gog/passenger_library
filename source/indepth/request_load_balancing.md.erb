---
title: Request load balancing
section: indepth
---
<% content_for(:sidebar) { render_partial("sidebar.html", locals: locals) } %>

# Request load balancing

At its core, Passenger is a process manager and HTTP request router. In order to minimize response times, and to distribute load over multiple CPU cores for optimal performance, Passenger load balances requests over processes in a "least busy process first" manner.

## How it works

<% if language_type == :ruby || language_type == :python %>
<% if language_type == :ruby %>
  Ruby apps can normally handle only 1 request at the same time.
<% else %>
  Python apps can only handle 1 request at the same time.
<% end %> 
With Passenger this is improved by running multiple instances of the app using pooled application groups. For each request from the incoming request queue, a non-busy (free) app instance is selected to handle the request.
<div><img src="../request_load_balancing.png"/></div>

<% if language_type == :ruby %>
  For thread-safe Ruby apps it is also possible to enable multithreading, which allows the app instance to concurrently handle multiple requests at the same time - up to the amount of threads configured. In this case, Passenger forwards the request to the instance that is currently handling the least number of requests.
<% end %>

If all application instances and threads are busy, Passenger spawns a new instance, up to the instance limit for the group. The amount of instances of the groups combined may also not exceed the limit for the application pool. If either limit is reached, the request remains in the queue (which has its own [limit](#request-queue-overflow)).
<% else %>
<%= language_name %> apps normally execute in a single thread/process, using a single CPU core. Passenger enables running multiple instances of the app using pooled application groups, distributing requests to the instance that is currently handling the least amount of requests.

<div><img src="../request_load_balancing.png"/></div>

In this way, load can be distributed across multiple cores without using cluster programming. Assuming a properly written asynchronous app, incoming requests will be handled concurrently (i.e. the next request can already start being handled while the previous is still being handled), and the Passenger request queue will remain empty.

<% end %>

<% if language_type == :ruby || language_type == :python %>
### No head-of-line blocking problem

Many web servers and load balancers use independent queues, which causes the problem of head-of-line blocking, whereby HTTP requests to your app are queued behind slow or long-running requests. Passenger avoids this problem by using a single (per application group) shared queue.

Imagine a supermarket with a number of (independent) checkout lanes and a queue in each of them. If someone in one of the queues has trouble with the checkout, everyone already in that queue will be delayed, which is especially unfair if the other queues keep moving fast.

Instead, the Passenger implementation can be compared to using a single (shared) queue and sending only 1 person per checkout lane at a time, thereby preventing head-of-line blocking.
<% end %>

## Customized balancing

By default, all requests for an application are balanced in a fair way. You may want to adjust this behavior; for example if your app consists of pages for visitors as well as some kind of webservice, you probably want to make sure the visitor requests don't get stuck behind webservice requests when under heavy load.

This can be solved by configuring two application groups for your app: one for the webservice URL and one for the visitor pages, each with their own request queue. The requests for the visitor pages will keep being handled even if there is an overload of requests for the webservice. See the [app group name](<%= url_for "/config/reference/index.html" %>?a=passenger_app_group_name) option.

The two application groups will still compete with each other for server resources. You can control how many instances are allowed per application group, for example allowing more instances to serve the visitor pages than the webservice URL. See the [max instances](<%= url_for "/config/reference/index.html" %>?a=passenger_max_instances) option.

<% if language_type == :ruby || language_type == :python %>
## Request queue overflow

If a request arrives for an application group, and all its instances are busy, and the application pool is full, the request remains in the Passenger request queue. If this keeps happening (e.g. due to a flood of requests) the queue will eventually overflow its limit (see: [max request queue size](<%= url_for "/config/reference/index.html" %>?a=passenger_max_request_queue_size)). Overflowing requests will no longer be balanced, but simply dropped (with a HTTP 503 error).
<% end %>